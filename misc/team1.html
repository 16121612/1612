<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN">
<html>
<head>
  <title>Ethical Reflections Team1</title>
   	<link rel="stylesheet" href="../styles/minimal-table.css" type="text/css">
</head>

<body>
<!-- Site navigation menu -->
<ul class="navbar">
  <li><a href="../index.html">Home</a>
  <li><a href="ethics.html">Ethical Reflections</a> 
  <li><a href="process.html">Process Support</a>
</ul>

<h1>Ethical Reflections Team Member 1 [Individual Page]</h1><br>
<p>Team name ____________________________________________________</p>

<p><h4>Student name: Joseph Stevenson, id: 18036380, </p></h4>


<h2>Ethical issues relating to the technology, your personal reflections and recommendations </h2>

<h4><em>[Note: Your individual and unique perspective on the topic/issue].</em></h4><br>


As Tesla and other self-driving car manufacturers have full control over the code that is being run on the car there are several issues such as safety, liability, proprietorship and privacy. As people inside the car need to trust the self-driving AI to not drive them into the ocean or create any other incident, over time people tend to become somewhat complacent and take more risks when driving as they know that the self-driving AI is designed to drive more conservatively. When accidents do happen while the car is being controlled by self-driving AI who is at fault? The person in the drivers’ seat or the AI? There has been quite a bit of debate over this topic as self-driving cars have become more mainstream over the recent years and as (Di, Chen, & Talley, 2020) states “In summary, on the top level, the lawmaker is the leader to make a high-level decision on the driver liability rule and the product liability rule.” which means that the law is the final decision when it comes to liability however, manufacturers will still need to keep to a certain safety standard when it comes to how the AI can react to situations and how many sensors or parts it needs to be able to road legal. And if those parts degrade or are destroyed over time are car manufacturers required to replace them to keep at that safety standard level? As the code for self-driving AI is kept closed source and proprietary there is no way to know what is being tracked and potentially sensitive data may be recorded by manufacturers and sold off to third parties that can then use it for any kind of unethical purpose. If the code was open sourced people would be able to tell exactly what is happening at any point in time. This may have negative impacts such as hackers being able to exploit the software much easier as the code is freely accessible which can lead to injury or loss of life if the hacker is able to exploit the self-driving AI’s systems.

Bibliography
Di, X., Chen, X., & Talley, E. (2020). Liability Design for Autonomous Vehicles and Human-Driven Vehicles: A Hierarchical Game-Theoretic Approach. Transportation Research Part C: Emerging Technologies 118, 102710. doi:https://doi.org/10.1016/j.trc.2020.102710



		




</html>
